name: ğŸš€ Deploy EKS Infrastructure and Application

on:
  push:
    branches: [ "main", "dev" ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v3

    - name: ğŸ›¡ Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    # ----------------- Build Number (Auto Increment) -----------------
    - name: ğŸ”¢ Generate Build Tag
      id: buildnumber
      run: |
        echo "BUILD_TAG=${GITHUB_RUN_NUMBER}" >> $GITHUB_OUTPUT
        echo "Using build tag: ${GITHUB_RUN_NUMBER}"

    # ----------------- Terraform Deploy -----------------
    - name: ğŸ“¦ Install Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.7.4

    - name: ğŸ§± Terraform Init
      working-directory: terraform/environments/dev
      run: terraform init

    - name: ğŸ“ Terraform Plan
      working-directory: terraform/environments/dev
      run: terraform plan

    - name: ğŸ“ Terraform Apply
      working-directory: terraform/environments/dev
      run: terraform apply -auto-approve

    - name: ğŸ” Verify Access Entry
      run: |
        echo "Verifying EKS access entry configuration..."
        aws eks describe-access-entry \
          --cluster-name eks-devops-cluster \
          --principal-arn arn:aws:iam::400338099943:user/AIDevOpsUser \
          --region us-west-2 || echo "âš ï¸  Could not verify access entry (this is OK if it doesn't exist yet)"

    # ----------------- Docker Build & Push -----------------
    - name: ğŸ” Login to ECR
      uses: aws-actions/amazon-ecr-login@v2

    - name: ğŸ”¨ Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: ğŸ›  Build & Push Multi-Arch Image
      working-directory: frontend-app
      run: |
        IMAGE_TAG=${{ steps.buildnumber.outputs.BUILD_TAG }}
        ECR_REPO=400338099943.dkr.ecr.us-west-2.amazonaws.com/springboot-eks

        echo "ğŸš€ Building version: $IMAGE_TAG"

        docker buildx build \
          --platform linux/arm64,linux/amd64 \
          -t $ECR_REPO:$IMAGE_TAG \
          -t $ECR_REPO:latest \
          --push .

    # ----------------- Deploy to EKS -----------------
    - name: ğŸ§  Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.33.0'

    - name: ğŸ“¡ Update kubeconfig
      run: |
        aws eks update-kubeconfig \
          --region us-west-2 \
          --name eks-devops-cluster

    - name: ğŸ” Verify EKS Access
      run: |
        echo "Verifying EKS access permissions..."
        # With EKS access policies, permissions are managed by AWS, not Kubernetes RBAC
        # The access policy (AmazonEKSClusterAdminPolicy) is configured in Terraform
        kubectl auth can-i get deployments --all-namespaces && echo "âœ… Permissions verified" || echo "âš ï¸  Warning: Permission check failed - access policies may not be applied yet"

    - name: ğŸš€ Deploy to Kubernetes
      run: |
        IMAGE_TAG=${{ steps.buildnumber.outputs.BUILD_TAG }}
        ECR_REPO=400338099943.dkr.ecr.us-west-2.amazonaws.com/springboot-eks

        echo "Deploying image: $ECR_REPO:$IMAGE_TAG"

        # Apply Kubernetes manifests (excluding RBAC file - using EKS access policies instead)
        kubectl apply -f k8s/deployment.yaml
        kubectl apply -f k8s/service.yaml
        kubectl apply -f k8s/ingress.yaml

        # Update deployment image
        kubectl set image deployment/eks-devops-app \
          eks-devops-app=$ECR_REPO:$IMAGE_TAG \
          --namespace=default

    - name: âœ… Verify Rollout
      run: |
        kubectl rollout status deployment/eks-devops-app
        kubectl get pods -o wide
        kubectl get ingress
